<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Sooran Kim</title>

    <meta name="author" content="Sooran Kim">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Sooran Kim
                </p>
                <p>I am an undergraduate student at <strong><a href="https://www.yonsei.ac.kr/en_sc/">Yonsei University</a></strong>, double majoring in <strong>Psychology</strong> and <strong>Computer Science</strong>. 
                </p>
                <p>
                  My interest in AI, especially in <strong>computer vision</strong>, began during a cognitive psychology course. I found it fascinating that the way the human visual system perceives objects was similar to how Convolutional Neural Networks (CNNs) process visual information. This realization sparked my curiosity about AI and led me to explore the field of computer vision, eventually deciding to pursue a second major in Computer Science.
                </p>
                <p style="text-align:center">
                  <a href="mailto:naroosmik@yonsei.ac.kr">Email</a> &nbsp;/&nbsp;
                  <a href="data/SooranKimCV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://github.com/sooorankim/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/SooranKim.jpg"><img style="width:100%;max-width:100%;object-fit: cover; " alt="profile photo" src="images/SooranKim.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research Interests</h2>
                <p>
                  I'm currently exploring various areas in computer vision, with a particular interest in video-related topics.
                </p>
              </td>
            </tr>
          </tbody></table>



          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Education</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/yonsei.png" style="max-width:100%; height:auto;" alt="Yonsei"></td>
              <td width="75%" valign="center">
                <span class="papertitle">Yonsei University, Seoul Korea</span>
                <p><em>Mar 2022 - Present</em></p>
		<strong>B.A.</strong> in Psychology & <strong>B.S.</strong> in Computer Science
<!--
		<br>
		Advanced Major in Psychology and AI Convergence -->
		<br>  
		GPA: 4.11/4.3
	      </td>
            </tr>
          </tbody></table>





          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Experience</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cip.jpg" style="max-width:100%; height:auto;" alt="CIP Lab"></td>
              <td width="75%" valign="center">
                <span class="papertitle"><a href="https://www.ciplab.kr/">CIP Lab, Yonsei University</a></span>
                <p><em>Undergraduate Intern (Advisor: Seon Joo Kim) | Jan 2025 - present</em></p>
		<p>
  		</p>
	      </td>
            </tr>
		<!--  
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/vcc.jpg" style="max-width:100%; height:auto;" alt="VCC Lab"></td>
              <td width="75%" valign="center">
                <span class="papertitle"><a href="https://vcc.yonsei.ac.kr/home">VCC Lab, Yonsei University</a></span>
                <p><em>Undergraduate Research Assistant (Advisor: Sang Chul Chong) | Sept 2024 - Dec 2024</em></p>
		<p>
    		Earned 1 credit in the 'Psychology Research Project' course through weekly discussions with Prof. Chong, focusing on research in amodal completion and its application to computer vision.
  		</p>
	      </td>
            </tr> -->
		  
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/yai.png" style="max-width:100%; height:auto;" alt="YAI"></td>
              <td width="75%" valign="center">
                <span class="papertitle"><a href="https://y-ai.notion.site/Yonsei-Artificial-Intelligence-YAI-23fc16b649b64aa7bd0e2b6c1a68cd9d">YAI, Yonsei Artificial Intelligence Club</a></span>
                <p><em>14th, 15th Member, 16th President | Jul 2024 - Present</em></p>
		<p>
    		YAI, the first and only AI club at Yonsei University, focuses on studying the principles and applications of artificial intelligence. As a member, I actively engage in reading, presenting, and discussing computer vision papers with fellow members, and participate in various club activities, including projects.
  		</p>
	      </td>
            </tr>





          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Projects</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>



	<tr>
	  <td style="padding:20px;">
	    <span class="papertitle">No-data Imitation Learning for Robotics: Beyond Synthetic Videos ðŸ¤–</span>
	    <p><em>Apr 2025 â€“ May 2025</em></p>
	    <p>
	      A core challenge in robotics is the <strong>lack of high-quality expert demonstrations</strong>, especially for diverse and physically realistic tasks. As part of the 6th YAI Contest (YAICON), our team tackled this problem by reproducing and extending the <a href="https://arxiv.org/abs/2503.10626" target="_blank">NIL (No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models)</a> framework. NIL proposes training robot policies from videos generated by video diffusion modelsâ€”without any real-world data. Since the official code was not released, we implemented the entire NIL pipeline from scratch and applied it to a <strong>humanoid locomotion task</strong> using the HumanoidBench simulator.
	    </p>
	    <p>
	      While NIL originally uses only synthetic videos, we hypothesized that abundant <strong>raw human videos</strong> might offer more physically plausible guidance. We trained policies using four demonstration types: raw human videos, mesh-rendered videos (via SMPL), MuJoCo-rendered humanoid videos (via SMPL), and diffusion-generated videos. Our experiments showed that although final performance was limited due to insufficient hyperparameter tuning, raw videos may serve as a promising direction for future imitation learning research.
	    </p>
	    <p>
	      You can check out the project on <a href="https://github.com/gjaegal/VIL" target="_blank">GitHub</a>. While the model is not yet able to walk properly, the following result shows one of the more promising outputs.
	    </p>
		<img src="images/nil.gif" alt="Inference result" style="max-width:100%; height:auto;">
	      </td>
            </tr>



	    <tr>
      		<td style="padding:20px;">
                <span class="papertitle">Make Your Own Emoji ðŸ¤©</span>
                <p><em>Oct 2024 - Nov 2024</em></p>
		<p>
		As part of the 5th YAI Contest (YAICON) held from October to December 2024, I collaborated with a team of five to develop "Make Your Own Emoji," a tool for creating personalized video-like emojis from 3-5 photos. My role focused on fine-tuning the DreamBooth model on a GPU server to incorporate user-provided photos, enabling high-quality, customizable outputs. The fine-tuned images were converted into videos using the MOFA model, with features allowing users to define motion trajectories. This project was awarded 2nd place in the YAICON.
		</p>
		<p>
		You can check out the project on <a href="https://github.com/DongDong810/make-your-emoji">GitHub</a>. Below are qualitative inference results:
		</p>
		<div style="display: flex; justify-content: space-around; align-items: center;">
		    <img src="images/inf1.gif" alt="Inference result 1" style="max-width:30%; height:auto;">
		    <img src="images/inf2.gif" alt="Inference result 2" style="max-width:30%; height:auto;">
		    <img src="images/inf3.gif" alt="Inference result 3" style="max-width:30%; height:auto;">
		</div>
	      </td>
            </tr>		  

            
	    <tr>
      		<td style="padding:20px;">
                <span class="papertitle">Fine-tuning Detectron2 for Face Mosaic ðŸ˜Š</span>
                <p><em>Aug 2024</em></p>
		<p>
		As part of a toy project in the YAI, I worked with a team of four to develop a simple face mosaic tool using Detectron2. 
		Two team members were responsible for downloading datasets and implementing the data loader. My role focused on fine-tuning the Detectron2 framework using a GPU server, particularly training a pre-trained Mask R-CNN model to ensure accurate face detection. Another teammate handled the implementation of the mosaic effect. This project gave us the opportunity to explore practical applications of computer vision techniques in a collaborative setting. 
		</p>
		<p>
		You can check out the project on <a href="https://github.com/DongDong810/Face_Mosaic">GitHub</a>. Below is a simple inference result:
		</p>
		<img src="images/inf.gif" alt="Inference result" style="max-width:100%; height:auto;">
	      </td>
            </tr>
	</tbody></table>



          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Honors and Awards</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/kosaf.png" style="max-width:100%; height:auto;" alt="Yonsei"></td>
              <td width="75%" valign="center">
                <span class="papertitle">National Outstanding Scholarship, Korea Student Aid Foundation</span>
                <p><em>Fall 2024</em></p>
		Awarded to top students in humanities and social sciences under the Humanities 100-Year Initiative.
	      </td>
	    </tr>

		      
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/yonsei.png" style="max-width:100%; height:auto;" alt="Yonsei"></td>
              <td width="75%" valign="center">
                <span class="papertitle">Veritas Scholarship, Yonsei University</span>
                <p><em>Fall 2024, Spring 2023, Fall 2022</em></p>
		Awarded for academic excellence, based on GPA and credit completion.
	      </td>
            </tr>

<!--
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/yonsei.png" style="max-width:100%; height:auto;" alt="Yonsei"></td>
              <td width="75%" valign="center">
                <span class="papertitle">Excellence Scholarship in Advanced AI Convergence Major, Yonsei University</span>
                <p><em>Dec 2024</em></p>
		Awarded to students in the Advanced AI Convergence major for excellent academic performance in AI core courses.
	      </td>
	    </tr>

-->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/yonsei.png" style="max-width:100%; height:auto;" alt="Yonsei"></td>
              <td width="75%" valign="center">
                <span class="papertitle">Honor, Yonsei University</span>
                <p><em>Aug 2022</em></p>
		Awarded to students in the top 10% based on GPA.
	      </td>
	    </tr>
            
          </tbody></table>



          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Services</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>


		  
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/tutoring.jpg" style="max-width:100%; height:auto;" alt="Tutoring"></td>
              <td width="75%" valign="center">
                <span class="papertitle">Yonsei Tutoring Program</span>
                <p><em>Tutor | Mar 2024 - Jun 2024</em></p>
		<p>
    		Provided 15 hours of personalized tutoring across 8 sessions to a student from Kazakhstan, covering the course 'Understanding Psychology' and Korean conversation.
  		</p>
	      </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/dn.png" style="max-width:100%; height:auto;" alt="DN"></td>
              <td width="75%" valign="center">
                <span class="papertitle">Dongnyeok Community Childrenâ€™s Center</span>
                <p><em>Mentor & Instructor | Mar 2022 - Dec 2023</em></p>
		<p>
		Taught mathematics to middle and high school students. Based on my performance, I was contracted as an instructor in 2023, delivering structured lessons and accumulating 206.5 volunteer hours.
		</p>
	      </td>
            </tr>
          </tbody></table>


<!--
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Talks</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/ViT.jpg" style="max-width:100%; height:auto;" alt="ViT"></td>
              <td width="75%" valign="center">
                <span class="papertitle">Vision Transformer Presentation at YAI</span>
                <p><em>Date: Aug 14, 2024</em></p>
		Delivered a presentation on Vision Transformer (ViT) at YAI, providing a detailed explanation of the background, architecture, and performance of ViT, making the topic approachable for audiences with little prior knowledge. The presentation was based on the paper <a href="https://arxiv.org/abs/2010.11929">"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"</a>.
    		<br>
    		You can check out the presentation slides (PDF) <a href="slides/ViT.pdf">here</a>.
	      </td>
	    </tr>
		      
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/Amodal.jpg" style="max-width:100%; height:auto;" alt="Amodal Completion"></td>
              <td width="75%" valign="center">
                <span class="papertitle">Amodal Completion Presentation at YAI</span>
                <p><em>Date: Sept 11, 2024</em></p>
		Delivered a presentation on the new amodal completion paradigm proposed in the paper <a href="https://arxiv.org/abs/2312.15540">"Amodal Completion via Progressive Mixed Context Diffusion"</a>, with a focus on its application to amodal completion tasks.
    		<br>
    		You can check out the presentation slides (PDF) <a href="slides/Amodal Completion.pdf">here</a>.
	      </td>
            </tr>
          </tbody></table>

-->

		      
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Things I Love</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20">
	  <tbody>
	    <tr>
	      <td style="padding:20px;width:25%;vertical-align:middle">
	        <img src="images/climbing.jpg" style="max-width:100%; height:auto;" alt="Exercise">
	      </td>
	      <td width="75%" valign="center">
	        <span class="papertitle">Exercise</span>
	        <p>I donâ€™t always enjoy working out, but I love how I feel afterward. These days, I mostly go to the gym or do Pilates.</p>
	      </td>
	    </tr>
	    <tr>
	      <td style="padding:20px;width:25%;vertical-align:middle">
	        <img src="images/parasite.jpg" style="max-width:100%; height:auto;" alt="Parasite">
	      </td>
	      <td width="75%" valign="center">
	        <span class="papertitle">Parasite</span>
	        <p>I'm a huge fan of Bong Joon-ho, and <strong>Parasite</strong> is my all-time favorite movie. I watched it three times in theaters and countless more times on Netflixâ€”I've seen it so many times that I can recite the lines by heart.</p>
	      </td>
	    </tr>
	  </tbody>
	</table>
			  


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
